# 중급 프로젝트 2 협업 일지 (4팀 박은서)

## 오늘 할 일
* 복잡한 테이블 더 살펴보기(trial_access_log, trial_visit_info)
* 주요 분석 데이터 전처리 코드 완성하기
## 오늘 한 일
* 복잡한 테이블 더 살펴보기(trial_access_log, trial_visit_info)
> 두 테이블에서 각각 중복치 및 이상치, 두 테이블을 연관시켜 생각해야하는 중복치 및 이상치를 어떻게 해석할 수 있을지 생각해보고 분석 방향에 따라 어떻게 처리할 수 있을지를 구상해봤다.
* 주요 분석 데이터 전처리 코드 완성하기
> 오전까지 처리해야할 부분을 정리하고 팀원들과 함께 분석 방향을 확인하며 테이블 별 전처리 항목을 결정했다. 이후 잘 실행되는지, 코드가 너무 길지는 않은지 신경쓰면서 전처리 코드를 완성했다.
## 내일 할 일

## Codes
```ruby
# 문자열 -> datetime 변환, 마이크로초 삭제 (나중에 초단위까지 삭제하려면 replace 인자에 second=0 추가)

cols = ['date', 'first_enter_time', 'last_leave_time']

def datetime_changer(df, col_list):
    for col in col_list:
        df[col] = pd.to_datetime(df[col], errors='coerce')
        df[f'{col}'] = df[col].apply(
            lambda dt: dt.replace(microsecond=0) if pd.notnull(dt) else pd.NaT
        )
    return df

datetime_changer(trial_visit_info, cols)

trial_visit_info.head(3)
```
## Issues & Challenges
* 문제 : trial_access_log, trial_visit_info 테이블의 전처리가 까다로웠다. 한쪽은 실시간 로그, 한쪽은 후처리된 데이터인데다 서로 관련이 있다보니 어느 한 쪽을 선뜻 건드리기가 어려웠다. 그래도 팀원들과 파생 변수 후보 피쳐들을 보면서 어떤 처리가 용이할지 고민하다보니 갈피가 잡혔다.
## Notes & Ideas
* 아이디어 : 데이터에 결측치, 중복치, 이상치 등이 존재할 때 그냥 제거하기보다는 해당 값들을 더 자세히 살펴보려고 노력했다. 그랬더니 어떤 스토리로 설명할 수 있어 제거하지 않는 편이 나은 경우가 있었고, 확실히 오류이기에 제거하는 편이 나은 경우가 명확히 나뉘었다. 데이터에서 어떤 이상한 점이 보여도 우선은 해당 값이 왜 나왔는지 이해해보려고 하는 과정이 중요한 것 같다.
## Reflection
* 좋았던 점 : 오늘 집중력있게 전처리 코드까지 마무리할 수 있었다.
* 아쉬운 점 : 아쉬운 부분 없이 최선을 다해서, 오류없이 코드를 잘 마무리했다!
